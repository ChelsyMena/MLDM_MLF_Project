{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "518e3fa9af81cb03",
   "metadata": {},
   "source": [
    "# SVM Practice Session\n",
    "In this session, we will see how to use Support Vector Machines (SVM) to classify data. In a first time, we will work with generated data, and then we will use SVM to try and predict pulsars stars."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac0b95e29899d2f5",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7281a9fe34e05a3",
   "metadata": {},
   "source": [
    "## Data generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "576f3a783f65cb69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We generate 1000 points, with 2 features, and 2 classes\n",
    "# Let's pick a center for each class\n",
    "center1 = np.array([0, 0])\n",
    "center2 = np.array([1, 1])\n",
    "# We generate 500 points around each center, distributed normally\n",
    "data1 = np.random.normal(loc=center1, # mean\n",
    "                         scale=(0.5, 0.3), # std deviation\n",
    "                         size=(500, 2))\n",
    "data2 = np.random.normal(loc=center2, # mean\n",
    "                         scale=(0.3, 0.5), # std deviation\n",
    "                         size=(500, 2))\n",
    "# We create the labels\n",
    "labels1 = np.zeros(500)\n",
    "labels2 = np.ones(500)\n",
    "# We concatenate the data and the labels\n",
    "data1 = np.concatenate((data1, labels1.reshape(-1, 1)), axis=1)\n",
    "data2 = np.concatenate((data2, labels2.reshape(-1, 1)), axis=1)\n",
    "# We concatenate the two classes\n",
    "data = np.concatenate((data1, data2), axis=0)\n",
    "# We shuffle the data\n",
    "np.random.shuffle(data)\n",
    "# We split the data into train, and test sets (80% / 20 %)\n",
    "# (optional)\n",
    "# We make a dataframe to plot the data, with columns x, y, label, set\n",
    "# We save the data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1f10fb7363e7cc8",
   "metadata": {},
   "source": [
    "Let's plot the data, to see what it looks like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f254ebc9358679b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "987279fb04b9d8c3",
   "metadata": {},
   "source": [
    "## SVM \n",
    "\n",
    "Note : use the GridSearchCV() function from sklearn to find the best hyperparameters for the SVM model.\n",
    "In order to plot the results of the grid search, you may consider heatmaps.\n",
    "Howerever, you may notice that we are concidering 3 hyperparameters, which makes it impossible to plot in a 2D space, and a 3D heatmap may be hard to read.\n",
    "Hence, you may consider plotting only 2 hyperparameters at a time, and average over the third one !\n",
    "\n",
    "To get the results from GridSearchCV, you may use `grid.cv_results_[\"mean_test_score\"]` and `grid.cv_results_[\"params\"]` to get the mean test score and the hyperparameters used for each fold.\n",
    "A 'nice' way of getting a unified collection of the hyperparameters and their corresponding score would be a peice of code such as :\n",
    "```python\n",
    "d = []\n",
    "i=0\n",
    "for p in grid.cv_results_[\"params\"]:\n",
    "    d.append(p)\n",
    "    d[-1][\"result\"] = grid.cv_results_[\"mean_test_score\"][i]\n",
    "    i += 1\n",
    "print(d)\n",
    "``` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e5c5c2dcfd8a27e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We tune the hyperparameters : C, kernel, gamma\n",
    "# We make a classifier\n",
    "# We make a grid search using GridSearchCV()\n",
    "\n",
    "# Note: the cross-validation behind GridSearchCV automatically splits the data into\n",
    "# training and validation sets for each fold. It trains the model on the training set and\n",
    "# evaluates its performance on the validation set. This process is repeated for each fold,\n",
    "# and the average performance is used to assess the model's generalization ability.\n",
    "# GridSearchCV exhaustively tests all possible combinations of hyperparameters specified\n",
    "# in the hyperparams dictionary, and selects the combination that gives the best average\n",
    "# performance across all folds. This helps in finding the optimal hyperparameters for the\n",
    "# Support Vector Machine model without manually trying each combination.\n",
    "\n",
    "\n",
    "# We train it\n",
    "# We plot the accuracy as a function of the hyper parameters. Thinks of a 'smart' way of plotting it.\n",
    "# We print the best hyperparameters\n",
    "# We select the best model and print the accuracy on the test set\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9469f00dbd741e12",
   "metadata": {},
   "source": [
    "## We can also plot the decision boundary\n",
    "\n",
    "For better insight, we plot the decision boundary of the classifier with the hyperparameters : (C=1, kernel=\"linear\"), (C=1, kernel=\"rbf\"), (C=100, kernel=\"linear\"), (C=100, kernel=\"rbf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc6b78d29199a354",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {1: {'C': 1, 'kernel': 'linear'},\n",
    "          2: {'C': 1, 'kernel': 'rbf'},\n",
    "          3: {'C': 100, 'kernel': 'linear'},\n",
    "          4: {'C': 100, 'kernel': 'rbf'}}\n",
    "# We make the classifiers\n",
    "# We train them\n",
    "# We get the accuracy on the test set\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Note : In order to predict the full space xx, yy, you will need to use something as \n",
    "```python\n",
    "model.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "```\n",
    "Please, note the use of `np.c_` to concatenate the two arrays, and the use of `ravel()` to flatten the arrays."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "260286d5c69a8b98"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c55aefc11780ff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We create a grid of points\n",
    "x_min, x_max = data[:, 0].min() - 0.1, data[:, 0].max() + 0.1\n",
    "y_min, y_max = data[:, 1].min() - 0.1, data[:, 1].max() + 0.1\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, 0.01),\n",
    "                     np.arange(y_min, y_max, 0.01))\n",
    "\n",
    "# We plot the decision boundary for each classifier and print the accuracy on the test set\n",
    "\n",
    "\n",
    "for key, value in models.items():\n",
    "    # We predict the labels for each point in the grid\n",
    "    # We reshape the predictions to match the grid\n",
    "    # We plot the decision boundary\n",
    "    # We plot the data\n",
    "    \n",
    "\n",
    "# Note: the model has been trained on the whole training set for each plot, that's why we do not get the exact same test accuracy as with the grid search (which used cross-validation)."
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Real data - Pulsar stars\n",
    "\n",
    "Apply the same procedure as in the previous section to find the best parameters for the pulsar dataset using cross-fold validation. The data is to be found with along to this notebook. The files are :\n",
    "- pulsar_data_train.csv on which you must perform the training and validation\n",
    "- pulsar_data_test.csv on which you must test your model.\n",
    "The interest of having a separate 'test' file is that everybody can eveluate their model equialy. \n",
    "Competitions websites such as Kaggle keep there test dataset private to evaluate all participants' models on the same secrete data !\n",
    "\n",
    "### Description\n",
    "\n",
    "Pulsars are a rare type of Neutron star that produce radio emission detectable here on Earth. They are of considerable scientific interest as probes of space-time, the interstellar medium, and states of matter. Machine learning tools are now being used to automatically label pulsar candidates to facilitate rapid analysis. In particular, classification systems are widely adopted, which treat the candidate datasets as binary classification problems.\n",
    "\n",
    "### Heandling missing values\n",
    "\n",
    "Somes values of the features are missing. You can use the `SimpleImputer` from `sklearn.impute` to fill the missing values. Or any other method you prefer.\n",
    "\n",
    "You can load the data into a dataframe using the below code snippet:\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "input_file = \"pulsar_data_train.csv\"\n",
    "df = pd.read_csv(input_file)\n",
    "```\n",
    "\n",
    "### More information\n",
    "\n",
    "Refer to the project's instructions for more information on this part."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "eab9f0739060af75"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# TODO : Here you go ! Good luck ! :)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1ef710eb555a81e4",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "fe7cc46d30b4f057"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
